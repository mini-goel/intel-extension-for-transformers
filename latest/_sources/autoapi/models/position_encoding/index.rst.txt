:py:mod:`models.position_encoding`
==================================

.. py:module:: models.position_encoding

.. autoapi-nested-parse::

   Various positional encodings for the transformer.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   models.position_encoding.PositionEmbeddingSine
   models.position_encoding.PositionEmbeddingLearned




.. py:class:: PositionEmbeddingSine(num_pos_feats=64, temperature=10000, normalize=False, scale=None)




   This is a more standard version of the position embedding, very similar to the one
   used by the Attention is all you need paper, generalized to work on images.


.. py:class:: PositionEmbeddingLearned(num_pos_feats=256)




   Absolute pos embedding, learned.


